{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14aa06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3775cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "idg = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "357f4e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1439654 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = idg.flow_from_directory('D:\\split_heightmaps', \n",
    "                                          target_size = (256, 256), \n",
    "                                          batch_size = 16, \n",
    "                                          class_mode = None,\n",
    "                                          color_mode = 'grayscale',\n",
    "                                          classes = [''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "763c4fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.preprocessing.image.DirectoryIterator"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f809f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "channels = 1\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "img_rows, img_cols = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6013bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b2cc8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Conv2DTranspose, Reshape, Flatten\n",
    "from keras.layers import LeakyReLU, BatchNormalization, Dropout, Input, RandomFlip\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10db8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    generator = Sequential()\n",
    "    \n",
    "    # Starting size\n",
    "    d = 4\n",
    "    generator.add(Dense(d*d*256, kernel_initializer = RandomNormal(0, 0.02), input_dim = noise_dim))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    generator.add(Reshape((d, d, 256)))\n",
    "    \n",
    "    generator.add(Conv2DTranspose(128, (4, 4), strides = 2, padding = 'same', \n",
    "                                  kernel_initializer = RandomNormal(0, 0.02)))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Conv2DTranspose(128, (4, 4), strides = 2, padding = 'same', \n",
    "                                  kernel_initializer = RandomNormal(0, 0.02)))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Conv2DTranspose(128, (4, 4), strides = 2, padding = 'same', \n",
    "                                  kernel_initializer = RandomNormal(0, 0.02)))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Conv2DTranspose(128, (4, 4), strides = 2, padding = 'same', \n",
    "                                  kernel_initializer = RandomNormal(0, 0.02)))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Conv2DTranspose(128, (4, 4), strides = 2, padding = 'same', \n",
    "                                  kernel_initializer = RandomNormal(0, 0.02)))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Conv2DTranspose(128, (4, 4), strides = 2, padding = 'same', \n",
    "                                  kernel_initializer = RandomNormal(0, 0.02)))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Conv2D(channels, (2, 2), padding = 'same', activation = 'tanh', \n",
    "                         kernel_initializer = RandomNormal(0, 0.02)))\n",
    "    \n",
    "    generator.compile(loss = binary_crossentropy, optimizer = optimizer)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "885e8378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    discriminator = Sequential()\n",
    "    \n",
    "    discriminator.add(Input(shape=(img_cols, img_rows, channels)))\n",
    "    discriminator.add(RandomFlip('horizontal_and_vertical'))\n",
    "    discriminator.add(Conv2D(64, (3, 3), padding = 'same', kernel_initializer = RandomNormal(0, 0.02)))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    discriminator.add(Conv2D(128, (3, 3), strides = 2, padding = 'same', kernel_initializer = RandomNormal(0, 0.02)))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    discriminator.add(Conv2D(128, (3, 3), strides = 2, padding = 'same', kernel_initializer = RandomNormal(0, 0.02)))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    discriminator.add(Conv2D(128, (3, 3), strides = 2, padding = 'same', kernel_initializer = RandomNormal(0, 0.02)))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    discriminator.add(Conv2D(256, (3, 3), strides = 2, padding = 'same', kernel_initializer = RandomNormal(0, 0.02)))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dropout(0.4))\n",
    "    discriminator.add(Dense(1, activation = 'sigmoid', input_shape = (img_cols, img_rows, channels)))\n",
    "    \n",
    "    discriminator.compile(loss = binary_crossentropy, optimizer = optimizer)\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51c3a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan():\n",
    "    generator = create_generator()\n",
    "    discriminator = create_discriminator()\n",
    "\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    gan_input = Input(shape=(noise_dim,))\n",
    "    fake_image = generator(gan_input)\n",
    "\n",
    "    gan_output = discriminator(fake_image)\n",
    "\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    gan.compile(loss = binary_crossentropy, optimizer = optimizer)\n",
    "    \n",
    "    return generator, discriminator, gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81e0257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, gan, image_generator, epochs, batch_size):\n",
    "    steps_per_epoch = math.floor(image_generator.__len__() * batch_size)\n",
    "    \n",
    "    discriminator_labels = np.zeros(2 * batch_size)\n",
    "    discriminator_labels[:batch_size] = 0.9\n",
    "    generator_labels = np.ones(batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(steps_per_epoch):\n",
    "            noise = np.random.normal(0, 1, size = (batch_size, noise_dim))\n",
    "            \n",
    "            fake_images = generator.predict(noise)\n",
    "            real_images = image_generator.next()\n",
    "            combined_images = np.concatenate((real_images, fake_images))\n",
    "\n",
    "            discriminator_loss = discriminator.train_on_batch(combined_images, discriminator_labels)\n",
    "            generator_loss = gan.train_on_batch(noise, generator_labels)\n",
    "\n",
    "        print(f'Epoch: {epoch} \\t Discriminator Loss: {discriminator_loss} \\t\\t Generator Loss: {generator_loss}')\n",
    "        \n",
    "    return generator, discriminator, gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321f982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator, discriminator, gan = train_gan(*create_gan(), \n",
    "                                          image_generator = train_generator, \n",
    "                                          epochs = 1, \n",
    "                                          batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3af90c24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2324\\1778078161.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/saved_models/big_one.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "generator.save('data/saved_models/big_one.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a5c1f7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2324\\2475275978.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;31m# The transformation of images is not under thread lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;31m# so it can be done in parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    340\u001b[0m           \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m           \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m           keep_aspect_ratio=self.keep_aspect_ratio)\n\u001b[0m\u001b[0;32m    343\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m       \u001b[1;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    392\u001b[0m       \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m       \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     raise TypeError('path should be path-like or io.BytesIO'\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "805cf31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89979"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "484f7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c254d095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.batch_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40d2bc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37692 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = idg.flow_from_directory('data/split_heightmaps', \n",
    "                                          target_size = (256, 256), \n",
    "                                          batch_size = 16, \n",
    "                                          class_mode = None,\n",
    "                                          color_mode = 'grayscale',\n",
    "                                          classes = [''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdee9be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(test_generator.__len__()):\n",
    "    print(i)\n",
    "    test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7012a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "266b342a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.batch_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "92f4fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bc8b76cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2324\\2713050504.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtest_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;31m# The transformation of images is not under thread lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;31m# so it can be done in parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    340\u001b[0m           \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m           \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m           keep_aspect_ratio=self.keep_aspect_ratio)\n\u001b[0m\u001b[0;32m    343\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m       \u001b[1;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;31m# convert it to an 8-bit grayscale image.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'L'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'I;16'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'I'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m       \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'L'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rgba'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'RGBA'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    932\u001b[0m         \"\"\"\n\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"transparency\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                             \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1fbeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
